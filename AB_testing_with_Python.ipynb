{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B testing: A step-by-step guide of how to design and analyse an A/B test experiment in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll go over the process of analysing an A/B test from formulating a hypothesis, testing it, and finally interpreting results. For our data, we'll use a <a href='https://www.kaggle.com/zhangluyuan/ab-testing?select=ab_data.csv'>dataset from Kaggle</a> which contains the results of an A/B test on 2 different designs of a website page (old_page vs. new_page).\n",
    "\n",
    "Here's what we'll do:\n",
    "\n",
    "1. [Designing our experiment](#1.-Designing-our-experiment)\n",
    "2. [Collecting and preparing the data](#2.-Collecting-and-preparing-the-data)\n",
    "3. [Visualising the results](#3.-Visualising-the-results)\n",
    "4. [Testing the hypothesis](#4.-Testing-the-hypothesis)\n",
    "5. [Drawing conclusions](#5.-Drawing-conclusions)\n",
    "\n",
    "To make it a bit more realistic, here's a potential **scenario** for our study inspired from a real project I worked on for an e-commerce business:\n",
    "\n",
    "> Let's imagine you work on the product team at a medium-sized **online e-commerce business**. The UX designer worked on a new version of the product page, with the hope that it will lead to a higher conversion rate. The product manager (PM) told you that the **current conversion rate** is about **13%** on average throughout the year, and that the team would be happy with an **increase of 2%**, meaning that the new design will be considered a success if it raises the conversion rate to 15%.\n",
    "\n",
    "Before rolling out the change, the team would be more comfortable testing it on a small number of users to see how it performs, so you suggest running an **A/B test** on a subset of your user base users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Designing our experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulating a hypothesis\n",
    "\n",
    "First things first, we want to make sure we formulate a hypothesis at the start of our project. This will make sure our interpretation of the results is correct as well as rigorous.\n",
    "\n",
    "Given we don't know if the new design will perform better or worse (or the same?) as our current design, we'll choose a <a href=\"https://en.wikipedia.org/wiki/One-_and_two-tailed_tests\">**two-tailed test**</a>:\n",
    "\n",
    "$$H_0: p = p_0$$\n",
    "$$H_a: p \\ne p_0$$\n",
    "\n",
    "where $p$ and $p_0$ stand for the conversion rate of the new and old design, respectively. We'll also set a **confidence level of 95%**:\n",
    "\n",
    "$$\\alpha = 0.05$$\n",
    "\n",
    "The $\\alpha$ value is a threshold we set, by which we say \"if the probability of observing a result as extreme or more ($p$-value) is lower than $\\alpha$, then we reject the null hypothesis\". Since our $\\alpha=0.05$ (indicating 5% probability), our confidence (1 - $\\alpha$) is 95%.\n",
    "\n",
    "Don't worry if you are not familiar with the above, all this really means is that whatever conversion rate we observe for our new design in our test, we want to be 95% confident it is statistically different from the conversion rate of our old design, before we decide to reject the Null hypothesis $H_0$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
